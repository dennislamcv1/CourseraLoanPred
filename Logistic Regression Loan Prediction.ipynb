{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Loan Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    "\n",
    "![image](desc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(60000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 60 seconds\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import count_nonzero, median, mean\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "#import squarify\n",
    "\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "# Import variance_inflation_factor from statsmodels\n",
    "# from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "# Import Tukey's HSD function\n",
    "# from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "import datetime\n",
    "from datetime import datetime, timedelta, date\n",
    "\n",
    "# import shap\n",
    "# import eli5\n",
    "# from IPython.display import display\n",
    "\n",
    "#import os\n",
    "#import zipfile\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from scipy.stats.mstats import normaltest # D'Agostino K^2 Test\n",
    "from scipy.stats import boxcox\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, OneHotEncoder, PolynomialFeatures\n",
    "\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "\n",
    "from sklearn.metrics import accuracy_score, auc, classification_report, confusion_matrix, f1_score, roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.feature_selection import f_regression, f_classif, chi2, RFE, RFECV\n",
    "from sklearn.feature_selection import mutual_info_regression, mutual_info_classif\n",
    "from sklearn.feature_selection import VarianceThreshold, GenericUnivariateSelect\n",
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, SelectPercentile\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB, CategoricalNB\n",
    "\n",
    "import imblearn\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler, CondensedNearestNeighbour\n",
    "from imblearn.under_sampling import EditedNearestNeighbours, TomekLinks\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE \n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "\n",
    "\n",
    "import feature_engine\n",
    "\n",
    "from feature_engine.selection import DropConstantFeatures, DropDuplicateFeatures \n",
    "from feature_engine.selection import DropCorrelatedFeatures, SmartCorrelatedSelection\n",
    "from feature_engine.selection import SelectBySingleFeaturePerformance\n",
    "\n",
    "import pycaret\n",
    "from pycaret.classification import *\n",
    "\n",
    "%matplotlib inline\n",
    "#sets the default autosave frequency in seconds\n",
    "%autosave 60 \n",
    "sns.set_style('dark')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "plt.rc('axes', titlesize=9)\n",
    "plt.rc('axes', labelsize=14)\n",
    "plt.rc('xtick', labelsize=12)\n",
    "plt.rc('ytick', labelsize=12)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# This module lets us save our models once we fit them.\n",
    "# import pickle\n",
    "\n",
    "pd.set_option('display.max_columns',None)\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.float_format','{:.2f}'.format)\n",
    "\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Data Glance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"trainmod2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>loanamount</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>monthsemployed</th>\n",
       "      <th>numcreditlines</th>\n",
       "      <th>interestrate</th>\n",
       "      <th>loanterm</th>\n",
       "      <th>dtiratio</th>\n",
       "      <th>degree</th>\n",
       "      <th>masters</th>\n",
       "      <th>highschool</th>\n",
       "      <th>fulltime</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>selfemployed</th>\n",
       "      <th>divorced</th>\n",
       "      <th>married</th>\n",
       "      <th>hasmortgage</th>\n",
       "      <th>hasdependents</th>\n",
       "      <th>otherloans</th>\n",
       "      <th>autoloans</th>\n",
       "      <th>businessloans</th>\n",
       "      <th>homeloans</th>\n",
       "      <th>hascosigner</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56</td>\n",
       "      <td>85994</td>\n",
       "      <td>50587</td>\n",
       "      <td>520</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>15.23</td>\n",
       "      <td>36</td>\n",
       "      <td>0.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>50432</td>\n",
       "      <td>124440</td>\n",
       "      <td>458</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>4.81</td>\n",
       "      <td>60</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46</td>\n",
       "      <td>84208</td>\n",
       "      <td>129188</td>\n",
       "      <td>451</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>21.17</td>\n",
       "      <td>24</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>32</td>\n",
       "      <td>31713</td>\n",
       "      <td>44799</td>\n",
       "      <td>743</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7.07</td>\n",
       "      <td>24</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>20437</td>\n",
       "      <td>9139</td>\n",
       "      <td>633</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6.51</td>\n",
       "      <td>48</td>\n",
       "      <td>0.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income  loanamount  creditscore  monthsemployed  numcreditlines  interestrate  loanterm  dtiratio  degree  masters  highschool  fulltime  unemployed  selfemployed  divorced  married  hasmortgage  hasdependents  otherloans  autoloans  businessloans  homeloans  hascosigner  default\n",
       "0   56   85994       50587          520              80               4         15.23        36      0.44       1        0           0         1           0             0         1        0            1              1           1          0              0          0            1        0\n",
       "1   69   50432      124440          458              15               1          4.81        60      0.68       0        1           0         1           0             0         0        1            0              0           1          0              0          0            1        0\n",
       "2   46   84208      129188          451              26               3         21.17        24      0.31       0        1           0         0           1             0         1        0            1              1           0          1              0          0            0        1\n",
       "3   32   31713       44799          743               0               3          7.07        24      0.23       0        0           1         1           0             0         0        1            0              0           0          0              1          0            0        0\n",
       "4   60   20437        9139          633               8               4          6.51        48      0.73       1        0           0         0           1             0         1        0            0              1           0          1              0          0            0        0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 255347 entries, 0 to 255346\n",
      "Data columns (total 25 columns):\n",
      " #   Column          Non-Null Count   Dtype  \n",
      "---  ------          --------------   -----  \n",
      " 0   age             255347 non-null  int64  \n",
      " 1   income          255347 non-null  int64  \n",
      " 2   loanamount      255347 non-null  int64  \n",
      " 3   creditscore     255347 non-null  int64  \n",
      " 4   monthsemployed  255347 non-null  int64  \n",
      " 5   numcreditlines  255347 non-null  int64  \n",
      " 6   interestrate    255347 non-null  float64\n",
      " 7   loanterm        255347 non-null  int64  \n",
      " 8   dtiratio        255347 non-null  float64\n",
      " 9   degree          255347 non-null  int64  \n",
      " 10  masters         255347 non-null  int64  \n",
      " 11  highschool      255347 non-null  int64  \n",
      " 12  fulltime        255347 non-null  int64  \n",
      " 13  unemployed      255347 non-null  int64  \n",
      " 14  selfemployed    255347 non-null  int64  \n",
      " 15  divorced        255347 non-null  int64  \n",
      " 16  married         255347 non-null  int64  \n",
      " 17  hasmortgage     255347 non-null  int64  \n",
      " 18  hasdependents   255347 non-null  int64  \n",
      " 19  otherloans      255347 non-null  int64  \n",
      " 20  autoloans       255347 non-null  int64  \n",
      " 21  businessloans   255347 non-null  int64  \n",
      " 22  homeloans       255347 non-null  int64  \n",
      " 23  hascosigner     255347 non-null  int64  \n",
      " 24  default         255347 non-null  int64  \n",
      "dtypes: float64(2), int64(23)\n",
      "memory usage: 48.7 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      23\n",
       "float64     2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>loanamount</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>monthsemployed</th>\n",
       "      <th>numcreditlines</th>\n",
       "      <th>interestrate</th>\n",
       "      <th>loanterm</th>\n",
       "      <th>dtiratio</th>\n",
       "      <th>degree</th>\n",
       "      <th>masters</th>\n",
       "      <th>highschool</th>\n",
       "      <th>fulltime</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>selfemployed</th>\n",
       "      <th>divorced</th>\n",
       "      <th>married</th>\n",
       "      <th>hasmortgage</th>\n",
       "      <th>hasdependents</th>\n",
       "      <th>otherloans</th>\n",
       "      <th>autoloans</th>\n",
       "      <th>businessloans</th>\n",
       "      <th>homeloans</th>\n",
       "      <th>hascosigner</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "      <td>255347.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.50</td>\n",
       "      <td>82499.30</td>\n",
       "      <td>127578.87</td>\n",
       "      <td>574.26</td>\n",
       "      <td>59.54</td>\n",
       "      <td>2.50</td>\n",
       "      <td>13.49</td>\n",
       "      <td>36.03</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.99</td>\n",
       "      <td>38963.01</td>\n",
       "      <td>70840.71</td>\n",
       "      <td>158.90</td>\n",
       "      <td>34.64</td>\n",
       "      <td>1.12</td>\n",
       "      <td>6.64</td>\n",
       "      <td>16.97</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.00</td>\n",
       "      <td>15000.00</td>\n",
       "      <td>5000.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>12.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>31.00</td>\n",
       "      <td>48825.50</td>\n",
       "      <td>66156.00</td>\n",
       "      <td>437.00</td>\n",
       "      <td>30.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>7.77</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>43.00</td>\n",
       "      <td>82466.00</td>\n",
       "      <td>127556.00</td>\n",
       "      <td>574.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>13.46</td>\n",
       "      <td>36.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>56.00</td>\n",
       "      <td>116219.00</td>\n",
       "      <td>188985.00</td>\n",
       "      <td>712.00</td>\n",
       "      <td>90.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>19.25</td>\n",
       "      <td>48.00</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69.00</td>\n",
       "      <td>149999.00</td>\n",
       "      <td>249999.00</td>\n",
       "      <td>849.00</td>\n",
       "      <td>119.00</td>\n",
       "      <td>4.00</td>\n",
       "      <td>25.00</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    income  loanamount  creditscore  monthsemployed  numcreditlines  interestrate  loanterm  dtiratio    degree   masters  highschool  fulltime  unemployed  selfemployed  divorced   married  hasmortgage  hasdependents  otherloans  autoloans  businessloans  homeloans  hascosigner   default\n",
       "count 255347.00 255347.00   255347.00    255347.00       255347.00       255347.00     255347.00 255347.00 255347.00 255347.00 255347.00   255347.00 255347.00   255347.00     255347.00 255347.00 255347.00    255347.00      255347.00   255347.00  255347.00      255347.00  255347.00    255347.00 255347.00\n",
       "mean      43.50  82499.30   127578.87       574.26           59.54            2.50         13.49     36.03      0.50      0.25      0.25        0.25      0.25        0.25          0.25      0.33      0.33         0.50           0.50        0.20       0.20           0.20       0.20         0.50      0.12\n",
       "std       14.99  38963.01    70840.71       158.90           34.64            1.12          6.64     16.97      0.23      0.43      0.43        0.43      0.43        0.43          0.43      0.47      0.47         0.50           0.50        0.40       0.40           0.40       0.40         0.50      0.32\n",
       "min       18.00  15000.00     5000.00       300.00            0.00            1.00          2.00     12.00      0.10      0.00      0.00        0.00      0.00        0.00          0.00      0.00      0.00         0.00           0.00        0.00       0.00           0.00       0.00         0.00      0.00\n",
       "25%       31.00  48825.50    66156.00       437.00           30.00            2.00          7.77     24.00      0.30      0.00      0.00        0.00      0.00        0.00          0.00      0.00      0.00         0.00           0.00        0.00       0.00           0.00       0.00         0.00      0.00\n",
       "50%       43.00  82466.00   127556.00       574.00           60.00            2.00         13.46     36.00      0.50      0.00      0.00        0.00      0.00        0.00          0.00      0.00      0.00         1.00           1.00        0.00       0.00           0.00       0.00         1.00      0.00\n",
       "75%       56.00 116219.00   188985.00       712.00           90.00            3.00         19.25     48.00      0.70      1.00      0.00        1.00      0.00        0.00          0.00      1.00      1.00         1.00           1.00        0.00       0.00           0.00       0.00         1.00      0.00\n",
       "max       69.00 149999.00   249999.00       849.00          119.00            4.00         25.00     60.00      0.90      1.00      1.00        1.00      1.00        1.00          1.00      1.00      1.00         1.00           1.00        1.00       1.00           1.00       1.00         1.00      1.00"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive Statistical Analysis\n",
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    225694\n",
       "1     29653\n",
       "Name: default, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.default.value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255347, 25)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'income', 'loanamount', 'creditscore', 'monthsemployed', 'numcreditlines', 'interestrate', 'loanterm', 'dtiratio', 'degree', 'masters', 'highschool', 'fulltime', 'unemployed', 'selfemployed', 'divorced', 'married', 'hasmortgage', 'hasdependents', 'otherloans', 'autoloans', 'businessloans', 'homeloans', 'hascosigner', 'default'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = pd.read_csv(\"testmod2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>loanamount</th>\n",
       "      <th>monthsemployed</th>\n",
       "      <th>interestrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>32</td>\n",
       "      <td>131645</td>\n",
       "      <td>43797</td>\n",
       "      <td>23</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>61</td>\n",
       "      <td>134312</td>\n",
       "      <td>18402</td>\n",
       "      <td>87</td>\n",
       "      <td>12.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>55</td>\n",
       "      <td>115809</td>\n",
       "      <td>151774</td>\n",
       "      <td>3</td>\n",
       "      <td>5.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>58</td>\n",
       "      <td>94970</td>\n",
       "      <td>55789</td>\n",
       "      <td>24</td>\n",
       "      <td>23.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>63</td>\n",
       "      <td>71727</td>\n",
       "      <td>189798</td>\n",
       "      <td>52</td>\n",
       "      <td>22.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  income  loanamount  monthsemployed  interestrate\n",
       "0   32  131645       43797              23          6.10\n",
       "1   61  134312       18402              87         12.99\n",
       "2   55  115809      151774               3          5.51\n",
       "3   58   94970       55789              24         23.93\n",
       "4   63   71727      189798              52         22.05"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For statsmodel, must add extra constant\n",
    "testset = sm.add_constant(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>loanamount</th>\n",
       "      <th>monthsemployed</th>\n",
       "      <th>interestrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.00</td>\n",
       "      <td>32</td>\n",
       "      <td>131645</td>\n",
       "      <td>43797</td>\n",
       "      <td>23</td>\n",
       "      <td>6.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>61</td>\n",
       "      <td>134312</td>\n",
       "      <td>18402</td>\n",
       "      <td>87</td>\n",
       "      <td>12.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.00</td>\n",
       "      <td>55</td>\n",
       "      <td>115809</td>\n",
       "      <td>151774</td>\n",
       "      <td>3</td>\n",
       "      <td>5.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>58</td>\n",
       "      <td>94970</td>\n",
       "      <td>55789</td>\n",
       "      <td>24</td>\n",
       "      <td>23.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.00</td>\n",
       "      <td>63</td>\n",
       "      <td>71727</td>\n",
       "      <td>189798</td>\n",
       "      <td>52</td>\n",
       "      <td>22.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   const  age  income  loanamount  monthsemployed  interestrate\n",
       "0   1.00   32  131645       43797              23          6.10\n",
       "1   1.00   61  134312       18402              87         12.99\n",
       "2   1.00   55  115809      151774               3          5.51\n",
       "3   1.00   58   94970       55789              24         23.93\n",
       "4   1.00   63   71727      189798              52         22.05"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (StatsModel)\n",
    "\n",
    "Explanation of some of the terms in the summary table:\n",
    "\n",
    "- coef : the coefficients of the independent variables in the regression equation.\n",
    "- Log-Likelihood : the natural logarithm of the Maximum Likelihood Estimation(MLE) function. MLE is the optimization process of finding the set of parameters that result in the best fit.\n",
    "- LL-Null : the value of log-likelihood of the model when no independent variable is included(only an intercept is included).\n",
    "- Pseudo R-squ. : a substitute for the R-squared value in Least Squares linear regression. It is the ratio of the log-likelihood of the null model to that of the full model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsm = df.iloc[:,0:24]\n",
    "ysm = df.iloc[:,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    56.,  85994.,  50587., ...,      0.,      0.,      1.],\n",
       "        [    69.,  50432., 124440., ...,      0.,      0.,      1.],\n",
       "        [    46.,  84208., 129188., ...,      0.,      0.,      0.],\n",
       "        ...,\n",
       "        [    56.,  84820., 208294., ...,      0.,      0.,      1.],\n",
       "        [    42.,  85109.,  60575., ...,      0.,      0.,      0.],\n",
       "        [    62.,  22418.,  18481., ...,      0.,      0.,      1.]]),\n",
       " array([0, 0, 1, ..., 0, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xsm.values, ysm.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xsm = sm.add_constant(Xsm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.315863\n",
      "         Iterations 7\n"
     ]
    }
   ],
   "source": [
    "logreg = sm.Logit(ysm, Xsm).fit(maxiter=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>        <td>default</td>     <th>  No. Observations:  </th>  <td>255347</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>255322</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    24</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Fri, 01 Sep 2023</td> <th>  Pseudo R-squ.:     </th>  <td>0.1205</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>20:23:02</td>     <th>  Log-Likelihood:    </th> <td> -80655.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -91705.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td> 0.000</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>          <td>   -0.4525</td> <td>    0.053</td> <td>   -8.597</td> <td> 0.000</td> <td>   -0.556</td> <td>   -0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>            <td>   -0.0394</td> <td>    0.000</td> <td>  -84.983</td> <td> 0.000</td> <td>   -0.040</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>         <td>-8.819e-06</td> <td> 1.71e-07</td> <td>  -51.699</td> <td> 0.000</td> <td>-9.15e-06</td> <td>-8.48e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loanamount</th>     <td> 4.257e-06</td> <td> 9.35e-08</td> <td>   45.555</td> <td> 0.000</td> <td> 4.07e-06</td> <td> 4.44e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>creditscore</th>    <td>   -0.0008</td> <td> 4.11e-05</td> <td>  -18.526</td> <td> 0.000</td> <td>   -0.001</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthsemployed</th> <td>   -0.0098</td> <td>    0.000</td> <td>  -51.104</td> <td> 0.000</td> <td>   -0.010</td> <td>   -0.009</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>numcreditlines</th> <td>    0.0887</td> <td>    0.006</td> <td>   15.193</td> <td> 0.000</td> <td>    0.077</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>interestrate</th>   <td>    0.0690</td> <td>    0.001</td> <td>   67.645</td> <td> 0.000</td> <td>    0.067</td> <td>    0.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loanterm</th>       <td>  8.98e-05</td> <td>    0.000</td> <td>    0.234</td> <td> 0.815</td> <td>   -0.001</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>dtiratio</th>       <td>    0.2811</td> <td>    0.028</td> <td>    9.969</td> <td> 0.000</td> <td>    0.226</td> <td>    0.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>degree</th>         <td>    0.1786</td> <td>    0.019</td> <td>    9.612</td> <td> 0.000</td> <td>    0.142</td> <td>    0.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>masters</th>        <td>    0.0459</td> <td>    0.019</td> <td>    2.413</td> <td> 0.016</td> <td>    0.009</td> <td>    0.083</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>highschool</th>     <td>    0.2567</td> <td>    0.018</td> <td>   13.947</td> <td> 0.000</td> <td>    0.221</td> <td>    0.293</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>fulltime</th>       <td>   -0.2816</td> <td>    0.019</td> <td>  -14.752</td> <td> 0.000</td> <td>   -0.319</td> <td>   -0.244</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>unemployed</th>     <td>    0.1628</td> <td>    0.018</td> <td>    9.191</td> <td> 0.000</td> <td>    0.128</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>selfemployed</th>   <td>   -0.0455</td> <td>    0.018</td> <td>   -2.483</td> <td> 0.013</td> <td>   -0.081</td> <td>   -0.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>divorced</th>       <td>    0.0659</td> <td>    0.016</td> <td>    4.220</td> <td> 0.000</td> <td>    0.035</td> <td>    0.097</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>married</th>        <td>   -0.1641</td> <td>    0.016</td> <td>  -10.122</td> <td> 0.000</td> <td>   -0.196</td> <td>   -0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hasmortgage</th>    <td>   -0.1570</td> <td>    0.013</td> <td>  -12.051</td> <td> 0.000</td> <td>   -0.183</td> <td>   -0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hasdependents</th>  <td>   -0.2434</td> <td>    0.013</td> <td>  -18.646</td> <td> 0.000</td> <td>   -0.269</td> <td>   -0.218</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>otherloans</th>     <td>    0.0096</td> <td>    0.020</td> <td>    0.467</td> <td> 0.640</td> <td>   -0.031</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>autoloans</th>      <td>    0.0184</td> <td>    0.020</td> <td>    0.902</td> <td> 0.367</td> <td>   -0.022</td> <td>    0.058</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>businessloans</th>  <td>    0.0624</td> <td>    0.020</td> <td>    3.082</td> <td> 0.002</td> <td>    0.023</td> <td>    0.102</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>homeloans</th>      <td>   -0.1763</td> <td>    0.021</td> <td>   -8.388</td> <td> 0.000</td> <td>   -0.217</td> <td>   -0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hascosigner</th>    <td>   -0.2710</td> <td>    0.013</td> <td>  -20.747</td> <td> 0.000</td> <td>   -0.297</td> <td>   -0.245</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                default   No. Observations:               255347\n",
       "Model:                          Logit   Df Residuals:                   255322\n",
       "Method:                           MLE   Df Model:                           24\n",
       "Date:                Fri, 01 Sep 2023   Pseudo R-squ.:                  0.1205\n",
       "Time:                        20:23:02   Log-Likelihood:                -80655.\n",
       "converged:                       True   LL-Null:                       -91705.\n",
       "Covariance Type:            nonrobust   LLR p-value:                     0.000\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "const             -0.4525      0.053     -8.597      0.000      -0.556      -0.349\n",
       "age               -0.0394      0.000    -84.983      0.000      -0.040      -0.039\n",
       "income         -8.819e-06   1.71e-07    -51.699      0.000   -9.15e-06   -8.48e-06\n",
       "loanamount      4.257e-06   9.35e-08     45.555      0.000    4.07e-06    4.44e-06\n",
       "creditscore       -0.0008   4.11e-05    -18.526      0.000      -0.001      -0.001\n",
       "monthsemployed    -0.0098      0.000    -51.104      0.000      -0.010      -0.009\n",
       "numcreditlines     0.0887      0.006     15.193      0.000       0.077       0.100\n",
       "interestrate       0.0690      0.001     67.645      0.000       0.067       0.071\n",
       "loanterm         8.98e-05      0.000      0.234      0.815      -0.001       0.001\n",
       "dtiratio           0.2811      0.028      9.969      0.000       0.226       0.336\n",
       "degree             0.1786      0.019      9.612      0.000       0.142       0.215\n",
       "masters            0.0459      0.019      2.413      0.016       0.009       0.083\n",
       "highschool         0.2567      0.018     13.947      0.000       0.221       0.293\n",
       "fulltime          -0.2816      0.019    -14.752      0.000      -0.319      -0.244\n",
       "unemployed         0.1628      0.018      9.191      0.000       0.128       0.197\n",
       "selfemployed      -0.0455      0.018     -2.483      0.013      -0.081      -0.010\n",
       "divorced           0.0659      0.016      4.220      0.000       0.035       0.097\n",
       "married           -0.1641      0.016    -10.122      0.000      -0.196      -0.132\n",
       "hasmortgage       -0.1570      0.013    -12.051      0.000      -0.183      -0.131\n",
       "hasdependents     -0.2434      0.013    -18.646      0.000      -0.269      -0.218\n",
       "otherloans         0.0096      0.020      0.467      0.640      -0.031       0.050\n",
       "autoloans          0.0184      0.020      0.902      0.367      -0.022       0.058\n",
       "businessloans      0.0624      0.020      3.082      0.002       0.023       0.102\n",
       "homeloans         -0.1763      0.021     -8.388      0.000      -0.217      -0.135\n",
       "hascosigner       -0.2710      0.013    -20.747      0.000      -0.297      -0.245\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg_pred = logreg.predict(exog=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pred_df = pd.DataFrame(logreg_pred, columns=[\"probability\"])\n",
    "# pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditions = [\n",
    "#     (pred_df['probability'] >= 0.5),\n",
    "#     (pred_df['probability'] < 0.5)\n",
    "#     ]\n",
    "\n",
    "# # create a list of the values we want to assign for each condition\n",
    "# values = [1.0,0.0]\n",
    "\n",
    "# # create a new column and use np.select to assign values to it using our lists as arguments\n",
    "# pred_df['predicted_probability'] = np.select(conditions, values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df.to_csv(\"statsmodelresults.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explain the Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model : OLS : Ordinary Least Squares : One way to create a linear regression model. Minimize the dependent samples so you can estimate the unknown samples when creating a linear regression model.\n",
    "\n",
    "Method : Least Squares : Fit data to the model by minimizing the residual samples\n",
    "\n",
    "R-squared : Measure of how well the regression line approximates the data points. If .5 then that is a sign that half of the observed variation can be explained by the models inputs. 1 would be perfectly correlated. \n",
    "\n",
    "Adj, R-squared : Reflects the fit of the model. Values range from 0 to 1, where higher values indicate a good fit.\n",
    "\n",
    "F-statistic : Measures how significantly the data points fit into the regression model by measuring variation of sample means. \n",
    "\n",
    "Prob (F-statistic) : Probability that the null hypothesis for the full model is true. Closer to zero the better the samples approach the model.\n",
    "\n",
    "Log-Likelihood : The conditional probability that the observed data fits the model\n",
    "\n",
    "AIC : Adjusts the log-likelihood based on the number of observations and complexity of the model. It focuses on the data points that best describe the data.\n",
    "\n",
    "Df Residuals : Degrees of freedom of the residuals which is the difference between predicted values and the measured data.\n",
    "\n",
    "BIC : We want a low BIC. It focuses on the shortest description of the data like AIC.\n",
    "\n",
    "Df Model : Number of parameters in the model\n",
    "\n",
    "Coefficient Constant : Is your Y intercept. If both dependent and independent coefficients are zero then the expected output would equal the constant coefficient.\n",
    "\n",
    "Independent Coefficient : Represents the change of the independent variable per unit.\n",
    "\n",
    "Standard Error : Accuracy of the coefficients\n",
    "\n",
    "P>|t| : The P Value. A P Value less than .05 is considered statistically significant.\n",
    "\n",
    "[.025 - .975] : Confidence Interval : Represents the range in which coefficients are likely to fall.\n",
    "\n",
    "Omnibus : (D’Angostino’s test) : Establishes whether the samples come from a normally distributed population.\n",
    "\n",
    "Durbin-Watson : Test to see if the errors are not independent. Used to find repeating patterns that may be obstructed by noise. Its value lies between 0 and 4. If greater than 2 this is a sign that relationships between two variables are going in opposite directions (negatively correlated). If less than 2 variables are positively correlated. \n",
    "\n",
    "Prob(Omnibus) : Probability of Omnibus\n",
    "\n",
    "Jarque-Bera : Tests whether the samples match a normal distribution. It never has a negative number and the further it gets from zero signals the data doesn't have a normal distribution. \n",
    "\n",
    "Skew : Measure of the asymmetry of the probability distribution. Negative skew indicates the tail is longer on the left and the concentration of the data is on the right. Positive indicates the tail is longer on the right. 0 indicates that the tails are balanced.\n",
    "\n",
    "Prob(JB) : The probability of Jarque-Bera\n",
    "\n",
    "Kurtosis : Describes the shape of a probability distribution with a focus on the tails and not the peak. If the value is high that is a sign that there are more outliers. If the value is less than 3 that means there are fewer outliers. A value of 3 points towards a normal distribution. Values greater than 3 indicate more outliers.\n",
    "\n",
    "Condition Number : Represents whether samples are highly related in our regression model. A large number indicates strong multicollinearity which means that independent variables are highly correlated with each other. This causes problems because a small number of samples are so dramatically different from others that results are corrupted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've prepared our data and we're ready to model. There's one last step before we can begin. We must split the data into features and target variable, and into training data and test data. We do this using the `train_test_split()` function. We'll put 25% of the data into our test set, and use the remaining 75% to train the model.\n",
    "\n",
    "Notice below that we include the argument `stratify=y`. If our master data has a class split of 80/20, stratifying ensures that this proportion is maintained in both the training and test data. `=y` tells the function that it should use the class ratio found in the `y` variable (our target).\n",
    "\n",
    "The less data you have overall, and the greater your class imbalance, the more important it is to stratify when you split the data. If we didn’t stratify, then the function would split the data randomly, and we could get an unlucky split that doesn’t get any of the minority class in the test data, which means we wouldn’t be able to effectively evaluate our model. Worst of all, we might not even realize what went wrong without doing some detective work.\n",
    "\n",
    "Lastly, we set a random seed so we and others can reproduce our work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(255347, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:24]\n",
    "y = df.iloc[:,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 225694, 1: 29653})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[    56.,  85994.,  50587., ...,      0.,      0.,      1.],\n",
       "        [    69.,  50432., 124440., ...,      0.,      0.,      1.],\n",
       "        [    46.,  84208., 129188., ...,      0.,      0.,      0.],\n",
       "        ...,\n",
       "        [    56.,  84820., 208294., ...,      0.,      0.,      1.],\n",
       "        [    42.,  85109.,  60575., ...,      0.,      0.,      0.],\n",
       "        [    62.,  22418.,  18481., ...,      0.,      0.,      1.]]),\n",
       " array([0, 0, 1, ..., 0, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((204277, 24), (51070, 24), (204277,), (51070,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({0: 180555, 1: 23722}), Counter({0: 45139, 1: 5931}))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing that you can usually try when modeling is scaling your predictor variables. Some models require you to scale the data in order for them to operate as expected, others don't. Naive Bayes does not require data scaling. However, sometimes packages and libraries need to make assumptions and approximations in their calculations. We're already breaking some of these assumptions by using the `GaussianNB` classifier on this dataset, and it may not be helping that some of our predictor variables are on very different scales. In general, scaling might not improve the model, but it probably won't make it worse. Let's try scaling our data.\n",
    "\n",
    "We'll use a function called `MinMaxScaler`, which we'll import from the `sklearn.preprocessing` module. `MinMaxScaler` normalizes each column so every value falls in the range of [0, 1]. The column's maximum value would scale to 1, and its minimum value would scale to 0. Everything else would fall somewhere between. This is the formula:\n",
    "\n",
    "$${x_{scaled}} = \\frac{x - x_{min}}{x_{max} - x_{min}}$$ \n",
    "\n",
    "To use a scaler, you must fit it to the training data, and transform both the training data _and_ the test data using that same scaler. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important transformations we need to apply to our data is feature scaling.  There are two common ways to get all attributes to have the same scale: min-max scaling and standardization.\n",
    "\n",
    "Min-max scaling (or normalization) is the simplest: values are shifted and rescaled so they end up ranging from 0 to 1. This is done by subtracting the min value and dividing by the max minus min.\n",
    "\n",
    "Standardization is different: first it subtracts the mean value (so standardized values always have a zero mean), and then it divides by the standard deviation, so that the resulting distribution has unit variance.\n",
    "\n",
    "Scikit-learn library provides `MinMaxScaler` for normalization and `StandardScaler` for standardization needs. For more information on `scikit-learn` [`MinMaxScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork837-2023-01-01) and [`StandardScaler`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML0232ENSkillsNetwork837-2023-01-01) please visit their respective documentation websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = minmax.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.43137255, 0.29389107, 0.07668634, ..., 1.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07843137, 0.52507056, 0.29288811, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.82352941, 0.3034541 , 0.98179169, ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.25490196, 0.64788628, 0.25228777, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.07843137, 0.59226365, 0.45717924, ..., 0.        , 1.        ,\n",
       "        1.        ],\n",
       "       [0.96078431, 0.7269165 , 0.66431971, ..., 0.        , 1.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.31372549, 0.61190824, 0.59297627, ..., 0.        , 1.        ,\n",
       "        0.        ],\n",
       "       [0.09803922, 0.80530967, 0.29172075, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.43137255, 0.49501848, 0.5335064 , ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       ...,\n",
       "       [0.50980392, 0.79510219, 0.98961216, ..., 0.        , 0.        ,\n",
       "        1.        ],\n",
       "       [0.66666667, 0.41318084, 0.91146458, ..., 0.        , 0.        ,\n",
       "        0.        ],\n",
       "       [0.05882353, 0.8433544 , 0.68560968, ..., 0.        , 0.        ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((204277, 24), (51070, 24), (204277,), (51070,))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection\n",
    "\n",
    "Feature selection is the process of choosing features to be used for modeling. In practice, feature selection takes place at multiple points in the PACE process. Although sometimes you will be given a dataset and a defined target variable, most often in practice you will begin with only a question or a problem that you are tasked with solving. In these cases, if you decide that the problem requires a model, you'll then have to:\n",
    "\n",
    "* Consider what data is available to you\n",
    "* Decide on what kind of model you need\n",
    "* Decide on a target variable\n",
    "* Assemble a collection of features that you think might help predict on your chosen target\n",
    "\n",
    "This would all take place during the **Plan** phase. \n",
    "\n",
    "Then, during the **Analyze** phase, you would perform EDA on the data and reevaluate your variables for appropriateness. For example, can your model handle null values? If not, what do you do with features with a lot of nulls? Perhaps you drop them. This too is feature selection.\n",
    "\n",
    "But it doesn't end there. Feature selection also occurs during the **Construct** phase. This usually involves building a model, examining which features are most predictive, and then removing the unpredictive features.\n",
    "\n",
    "There's a lot of work involved in feature selection. In our case, we already have a dataset, and we're not performing thorough EDA on it. But we can still examine the data to ensure that all the features can reasonably be expected to have predictive potential. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Methods (Other Methods)\n",
    "\n",
    "## Univariate Performance with Feature-engine\n",
    "\n",
    "This procedure works as follows:\n",
    "\n",
    "- Train a ML model per every single feature\n",
    "- Determine the performance of the models\n",
    "- Select features if model performance is above a certain threshold\n",
    "\n",
    "The C value in Logistic Regression is an user adjustable parameter that controls regularisation. In simple terms, higher values of C will instruct our model to fit the training set as best as possible, while lower C values will favour a simple models with coefficients closer to zero.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the machine learning model\n",
    "lr = LogisticRegression(penalty='l2', C=100.0, random_state=0, solver='lbfgs', max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the selector\n",
    "sel = SelectBySingleFeaturePerformance(\n",
    "    variables=None,\n",
    "    estimator=lr,\n",
    "    scoring=\"roc_auc\",\n",
    "    cv=5,\n",
    "    threshold=0.55\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectBySingleFeaturePerformance(cv=5,\n",
       "                                 estimator=LogisticRegression(C=100.0,\n",
       "                                                              max_iter=1000,\n",
       "                                                              random_state=0),\n",
       "                                 threshold=0.55)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find predictive features\n",
    "sel.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x0': 0.6499804069364623,\n",
       " 'x1': 0.5901114880801165,\n",
       " 'x2': 0.5770444277207419,\n",
       " 'x3': 0.5316347971503128,\n",
       " 'x4': 0.5871832045780309,\n",
       " 'x5': 0.5252181152793829,\n",
       " 'x6': 0.6178730821054315,\n",
       " 'x7': 0.49727438862236406,\n",
       " 'x8': 0.5183127157349864,\n",
       " 'x9': 0.5059573290181053,\n",
       " 'x10': 0.5098506217860879,\n",
       " 'x11': 0.5155457603516969,\n",
       " 'x12': 0.5257553248184827,\n",
       " 'x13': 0.523277294387045,\n",
       " 'x14': 0.5017849115027728,\n",
       " 'x15': 0.5149439485986871,\n",
       " 'x16': 0.5205447254499,\n",
       " 'x17': 0.5178152851894209,\n",
       " 'x18': 0.5274112534802616,\n",
       " 'x19': 0.501293477628224,\n",
       " 'x20': 0.5027502581014924,\n",
       " 'x21': 0.5073621880984038,\n",
       " 'x22': 0.5129063020499315,\n",
       " 'x23': 0.5315925801687633}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the transformer stores a dictionary of feature:metric pairs\n",
    "# notice that the roc can be positive or negative.\n",
    "# the selector selects based on the absolute value\n",
    "\n",
    "#In general, an AUC of 0.5 suggests no discrimination \n",
    "#(i.e., ability to diagnose patients with and without the disease or condition based on the test), \n",
    "#0.7 to 0.8 is considered acceptable, 0.8 to 0.9 is considered excellent, and more than 0.9 is considered outstanding\n",
    "\n",
    "sel.feature_performance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1440x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(sel.feature_performance_).sort_values(ascending=False).plot.bar(figsize=(20, 5))\n",
    "plt.title('Performance of ML models trained with individual features', size=15)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('ROC Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['x3',\n",
       " 'x5',\n",
       " 'x7',\n",
       " 'x8',\n",
       " 'x9',\n",
       " 'x10',\n",
       " 'x11',\n",
       " 'x12',\n",
       " 'x13',\n",
       " 'x14',\n",
       " 'x15',\n",
       " 'x16',\n",
       " 'x17',\n",
       " 'x18',\n",
       " 'x19',\n",
       " 'x20',\n",
       " 'x21',\n",
       " 'x22',\n",
       " 'x23']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the features that will be removed\n",
    "\n",
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>x11</th>\n",
       "      <th>x12</th>\n",
       "      <th>x13</th>\n",
       "      <th>x14</th>\n",
       "      <th>x15</th>\n",
       "      <th>x16</th>\n",
       "      <th>x17</th>\n",
       "      <th>x18</th>\n",
       "      <th>x19</th>\n",
       "      <th>x20</th>\n",
       "      <th>x21</th>\n",
       "      <th>x22</th>\n",
       "      <th>x23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x0   x1   x2   x3   x4   x5   x6   x7   x8   x9  x10  x11  x12  x13  x14  x15  x16  x17  x18  x19  x20  x21  x22  x23\n",
       "roc 0.65 0.59 0.58 0.53 0.59 0.53 0.62 0.50 0.52 0.51 0.51 0.52 0.53 0.52 0.50 0.51 0.52 0.52 0.53 0.50 0.50 0.51 0.51 0.53"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame(data=[sel.feature_performance_], index=[\"roc\"])\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.columns = X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>loanamount</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>monthsemployed</th>\n",
       "      <th>numcreditlines</th>\n",
       "      <th>interestrate</th>\n",
       "      <th>loanterm</th>\n",
       "      <th>dtiratio</th>\n",
       "      <th>degree</th>\n",
       "      <th>masters</th>\n",
       "      <th>highschool</th>\n",
       "      <th>fulltime</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>selfemployed</th>\n",
       "      <th>divorced</th>\n",
       "      <th>married</th>\n",
       "      <th>hasmortgage</th>\n",
       "      <th>hasdependents</th>\n",
       "      <th>otherloans</th>\n",
       "      <th>autoloans</th>\n",
       "      <th>businessloans</th>\n",
       "      <th>homeloans</th>\n",
       "      <th>hascosigner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>0.65</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  income  loanamount  creditscore  monthsemployed  numcreditlines  interestrate  loanterm  dtiratio  degree  masters  highschool  fulltime  unemployed  selfemployed  divorced  married  hasmortgage  hasdependents  otherloans  autoloans  businessloans  homeloans  hascosigner\n",
       "roc 0.65    0.59        0.58         0.53            0.59            0.53          0.62      0.50      0.52    0.51     0.51        0.52      0.53        0.52          0.50      0.51     0.52         0.52           0.53        0.50       0.50           0.51       0.51         0.53"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>loanamount</th>\n",
       "      <th>creditscore</th>\n",
       "      <th>monthsemployed</th>\n",
       "      <th>numcreditlines</th>\n",
       "      <th>interestrate</th>\n",
       "      <th>loanterm</th>\n",
       "      <th>dtiratio</th>\n",
       "      <th>degree</th>\n",
       "      <th>masters</th>\n",
       "      <th>highschool</th>\n",
       "      <th>fulltime</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>selfemployed</th>\n",
       "      <th>divorced</th>\n",
       "      <th>married</th>\n",
       "      <th>hasmortgage</th>\n",
       "      <th>hasdependents</th>\n",
       "      <th>otherloans</th>\n",
       "      <th>autoloans</th>\n",
       "      <th>businessloans</th>\n",
       "      <th>homeloans</th>\n",
       "      <th>hascosigner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>roc</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      age  income  loanamount  creditscore  monthsemployed  numcreditlines  interestrate  loanterm  dtiratio  degree  masters  highschool  fulltime  unemployed  selfemployed  divorced  married  hasmortgage  hasdependents  otherloans  autoloans  businessloans  homeloans  hascosigner\n",
       "roc  True    True        True        False            True           False          True     False     False   False    False       False     False       False         False     False    False        False          False       False      False          False      False        False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(features >= 0.55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age               1\n",
       "income            1\n",
       "loanamount        1\n",
       "creditscore       0\n",
       "monthsemployed    1\n",
       "numcreditlines    0\n",
       "interestrate      1\n",
       "loanterm          0\n",
       "dtiratio          0\n",
       "degree            0\n",
       "masters           0\n",
       "highschool        0\n",
       "fulltime          0\n",
       "unemployed        0\n",
       "selfemployed      0\n",
       "divorced          0\n",
       "married           0\n",
       "hasmortgage       0\n",
       "hasdependents     0\n",
       "otherloans        0\n",
       "autoloans         0\n",
       "businessloans     0\n",
       "homeloans         0\n",
       "hascosigner       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(features >= 0.55).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unwanted features (After feature selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['creditscore', 'numcreditlines', 'loanterm', 'dtiratio', 'degree', 'masters', 'highschool', \n",
    "         'fulltime', 'unemployed', 'selfemployed', 'divorced', 'married', \n",
    "         'hasmortgage', 'hasdependents', 'otherloans', 'autoloans', 'businessloans', \n",
    "         'homeloans', 'hascosigner'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"trainmod.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"trainmod.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:5]\n",
    "y = df.iloc[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.values, y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train), Counter(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = minmax.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled = minmax.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled.shape, X_test_scaled.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a random dataset for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random = df.sample(n=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random = df.sample(frac=0.25, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_random.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random = df_random.iloc[:,:24]\n",
    "y_random = df_random.iloc[:,24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random.values, y_random.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random_train, X_random_test, y_random_train, y_random_test = train_test_split(X_random, y_random, test_size=0.2, random_state=0, stratify=y_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random_train.shape, X_random_test.shape, y_random_train.shape, y_random_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_random_train), Counter(y_random_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minmax = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random_train_scaled = minmax.fit_transform(X_random_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random_test_scaled = minmax.transform(X_random_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_random_train_scaled, X_random_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Class Imbalance Treatment\n",
    "\n",
    "For many machine learning tasks on imbalanced datasets, like this credit card fraud detection, we normally care more about recall than precision. As a baseline, we want the model to be able to find all frauds and we would allow the model to make false-positive errors because the cost of false positives is usually not very high (maybe just costs a false notification email or phone call to confirm with customers). On the other hand, failing to recognize positive examples (such as fraud or a deadly disease) can be life-threatening \n",
    "\n",
    "As such, our priority is to improve the model's recall, then we will also want to keep precision as high as possible.\n",
    "\n",
    "## Class reweighting\n",
    "\n",
    "For binary classification models, its loss function is normally calculated via a sum of the loss with respect to class 0 and the loss with respect to class 1. By default, their class weights are all 1s meaning we treat each class equally important.\n",
    "\n",
    "However, since the class distribution is skewed in imbalanced datasets and the loss function optimization process will be dominated by the majority class, we want to help the minority class by increasing its class weight in the loss function.\n",
    "\n",
    "Class weights can be generally calculated via the following three strategies:\n",
    "\n",
    "- Based on their instances portion in the dataset. For example, if positive instances only take 10% of the dataset, we assign its weight to be 0.9 and weight for the majority class to be 0.1\n",
    "- Heuristics or domain knowledge. Misclassification normally has different costs per class, for example, the cost of failure to diagnose a disease is much higher than a false positive diagnose. If we already know such misclassification costs beforehand, we may use them to assign class weights\n",
    "- Hyper-parameter tuning. Standard hyper-parameter tuning methods can be used to find optimized class weights. For example, grid searching from 0.1 to 0.9 for positive class weight to find out which hyperparameter combination generates the best model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "LogisticRegression(class_weight={0: 0.1, 1: 0.9}, max_iter=1000, penalty='l1',\n",
    "                   random_state=0, solver='liblinear')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {}\n",
    "\n",
    "# Assign weight of class 0 to be 0.1\n",
    "class_weight[0] = 0.1\n",
    "\n",
    "# Assign weight of class 1 to be 0.9\n",
    "class_weight[1] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a logistic regression with weight\n",
    "logregw = LogisticRegression(random_state=0, \n",
    "                              max_iter = 1000,\n",
    "                              penalty='l1',\n",
    "                              class_weight=class_weight,\n",
    "                              solver='liblinear',\n",
    "                              C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "logregw.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "logregw_pred = logregw.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregw_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", \"%.3f\" % accuracy_score(y_test, logregw_pred))\n",
    "print(\"Precision:\", \"%.3f\" % precision_score(y_test, logregw_pred))\n",
    "print(\"Recall:\", \"%.3f\" % recall_score(y_test, logregw_pred))\n",
    "print(\"F1 Score:\", \"%.3f\" % f1_score(y_test, logregw_pred))\n",
    "print(\"ROC-AUC Score:\", \"%.3f\" % roc_auc_score(y_test, logregw_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression Reweighting Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregw_pred = logregw.predict(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregw_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(logregw_pred, columns=[\"predicted_probability\"])\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df.to_csv(\"lrweightingresults.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weights in Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a logistic regression with weight\n",
    "logregw2 = LogisticRegression(random_state=0, \n",
    "                              max_iter = 1000,\n",
    "                              class_weight=\"balanced\",\n",
    "                              C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "logregw2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "logregw_pred2 = logregw2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregw_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", \"%.3f\" % accuracy_score(y_test, logregw_pred2))\n",
    "print(\"Precision:\", \"%.3f\" % precision_score(y_test, logregw_pred2))\n",
    "print(\"Recall:\", \"%.3f\" % recall_score(y_test, logregw_pred2))\n",
    "print(\"F1 Score:\", \"%.3f\" % f1_score(y_test, logregw_pred2))\n",
    "print(\"ROC-AUC Score:\", \"%.3f\" % roc_auc_score(y_test, logregw_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling/Oversampling Overview\n",
    "\n",
    "Different techniques used:\n",
    "\n",
    "- Random Undersampling: RandomUnderSampler(sampling_strategy='auto', random_state=None, replacement=False)\n",
    "\n",
    "- Condensed Nearest Neighbours (CNN): CondensedNearestNeighbour(sampling_strategy='auto', random_state=None, n_neighbors=None, n_seeds_S=1, n_jobs=None)\n",
    "\n",
    "- Tomek Links\n",
    "- One Sided Selection\n",
    "- Edited Nearest Neighbours\n",
    "- Repeated Edited Nearest Neighbours\n",
    "- All KNN\n",
    "- Neighbourhood Cleaning Rule\n",
    "- NearMiss\n",
    "- Instance Hardness Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Under-Sampling\n",
    "\n",
    "Undersampling can be defined as removing some observations of the majority class. This is done until the majority and minority class is balanced out.\n",
    "\n",
    "Undersampling can be a good choice when you have a ton of data -think millions of rows. But a drawback to undersampling is that we are removing information that may be valuable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(sampling_strategy='auto', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rus, y_train_rus = rus.fit_resample(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_rus.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train), Counter(y_train_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {}\n",
    "\n",
    "# Assign weight of class 0 to be 0.1\n",
    "class_weight[0] = 0.1\n",
    "\n",
    "# Assign weight of class 1 to be 0.9\n",
    "class_weight[1] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a logistic regression with weight\n",
    "lrrus = LogisticRegression(random_state=0, \n",
    "                              max_iter = 1000,\n",
    "                              class_weight=None,\n",
    "                              C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lrrus.fit(X_train_rus, y_train_rus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "lrrus_pred = lrrus.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrrus_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", \"%.3f\" % accuracy_score(y_test, lrrus_pred))\n",
    "print(\"Precision:\", \"%.3f\" % precision_score(y_test, lrrus_pred))\n",
    "print(\"Recall:\", \"%.3f\" % recall_score(y_test, lrrus_pred))\n",
    "print(\"F1 Score:\", \"%.3f\" % f1_score(y_test, lrrus_pred))\n",
    "print(\"ROC-AUC Score:\", \"%.3f\" % roc_auc_score(y_test, lrrus_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,lrrus_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,lrrus_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=lrrus, X=X_test_scaled, y=y_test, ax=ax, display_labels=[\"No\",\"Yes\"])\n",
    "ax.set_title('Confusion matrix of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(estimator=lrrus, X=X_test_scaled, y=y_test, ax=ax)\n",
    "ax.set_title('ROC Curve of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Over-Sampling\n",
    "\n",
    "Oversampling can be defined as adding more copies to the minority class. Oversampling can be a good choice when you don’t have a ton of data to work with.\n",
    "\n",
    "A con to consider when undersampling is that it can cause overfitting and poor generalization to your test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy='auto', random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ros, y_train_ros = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_ros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_train), Counter(y_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {}\n",
    "\n",
    "# Assign weight of class 0 to be 0.1\n",
    "class_weight[0] = 0.1\n",
    "\n",
    "# Assign weight of class 1 to be 0.9\n",
    "class_weight[1] = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a logistic regression with weight\n",
    "lrros = LogisticRegression(random_state=0, \n",
    "                              max_iter = 1000,\n",
    "                              class_weight=None,\n",
    "                              C=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "lrros.fit(X_train_ros, y_train_ros)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test dataset\n",
    "lrros_pred = lrros.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrros_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", \"%.3f\" % accuracy_score(y_test, lrros_pred))\n",
    "print(\"Precision:\", \"%.3f\" % precision_score(y_test, lrros_pred))\n",
    "print(\"Recall:\", \"%.3f\" % recall_score(y_test, lrros_pred))\n",
    "print(\"F1 Score:\", \"%.3f\" % f1_score(y_test, lrros_pred))\n",
    "print(\"ROC-AUC Score:\", \"%.3f\" % roc_auc_score(y_test, lrros_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,lrros_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,lrros_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=lrros, X=X_test, y=y_test, ax=ax, display_labels=[\"No\",\"Yes\"])\n",
    "ax.set_title('Confusion matrix of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(estimator=lrros, X=X_test, y=y_test, ax=ax)\n",
    "ax.set_title('ROC Curve of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression (Scikit Learn)\n",
    "\n",
    "**Logistic Regression model assumptions**\n",
    "- Outcome variable is categorical\n",
    "- Observations are independent of each other\n",
    "- No severe multicollinearity among X variables\n",
    "- No extreme outliers\n",
    "- Linear relationship between each X variable and the logit of the outcome variable\n",
    "- Sufficiently large sample size\n",
    "\n",
    "Let's build our model using **LogisticRegression** from the Scikit-learn package. This function implements logistic regression and can use different numerical optimizers to find parameters, including ‘newton-cg’, ‘lbfgs’, ‘liblinear’, ‘sag’, ‘saga’ solvers. You can find extensive information about the pros and cons of these optimizers if you search it in the internet.\n",
    "\n",
    "The version of Logistic Regression in Scikit-learn, support regularization. Regularization is a technique used to solve the overfitting problem of machine learning models.\n",
    "**C** parameter indicates **inverse of regularization strength** which must be a positive float. Smaller values specify stronger regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "## RandomSearchCV\n",
    "\n",
    "Randomised grid search is very useful in finding near-optimal hyper parameters for any machine learning models.\n",
    "\n",
    "Rules of thumb: with 60 iterations, 95% of the time, best 5% sets of parameters can be found, regardless of grid size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "               'penalty' : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "               'C':  [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm = RandomizedSearchCV(estimator=logreg, param_distributions = parameters, cv = 5, n_iter = 60, \n",
    "                           n_jobs=-1, scoring=scoring, refit='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_randm.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model_name (string): what you want the model to be called in the output table\n",
    "        model_object: a fit GridSearchCV object\n",
    "        metric (string): precision, recall, f1, accuracy, or auc\n",
    "  \n",
    "    Returns a pandas df with the F1, recall, precision, accuracy, and auc scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.  \n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {\n",
    "                 'precision': 'mean_test_precision',\n",
    "                 'recall': 'mean_test_recall',\n",
    "                 'f1': 'mean_test_f1',\n",
    "                 'accuracy': 'mean_test_accuracy',\n",
    "                 'roc_auc' : 'mean_test_roc_auc'\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    \n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "    roc_auc = best_estimator_results.mean_test_roc_auc\n",
    "  \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame()\n",
    "    table = table.append({'Model': model_name,\n",
    "                        'Precision': precision,\n",
    "                        'Recall': recall,\n",
    "                        'F1': f1,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'ROC-AUC' : roc_auc\n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "  \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all CV scores\n",
    "lr_cv_results = make_results('Logistic Regression', lr_randm, 'roc_auc')\n",
    "lr_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {}\n",
    "\n",
    "# Assign weight of class 0 to be 0.1\n",
    "class_weight[0] = 0.05\n",
    "\n",
    "# Assign weight of class 1 to be 0.9\n",
    "class_weight[1] = 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtuned = lr_randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logregtuned = LogisticRegression(penalty='l1', C=1.0, max_iter=1000, random_state=0, solver='liblinear', class_weight=class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtuned.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtuned_pred = logregtuned.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtuned_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtuned.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtuned.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtuned.score(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtuned.score(X_test_scaled, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,logregtuned_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,logregtuned_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=logregtuned, X=X_test_scaled, y=y_test, ax=ax, display_labels=[\"No\",\"Yes\"])\n",
    "ax.set_title('Confusion matrix of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(estimator=logreg, X=X_test_scaled, y=y_test, ax=ax)\n",
    "ax.set_title('ROC Curve of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the generalization error of a machine learning model using Cross-Validation Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate generalization error\n",
    "clf = cross_validate(estimator=logreg,\n",
    "                    X=X_train_scaled,\n",
    "                    y=y_train,\n",
    "                    scoring='roc_auc',\n",
    "                    return_train_score=True,\n",
    "                    cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean test set roc-auc\n",
    "clf[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean train set roc-auc\n",
    "clf[\"train_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrtable = pd.DataFrame()\n",
    "lrtable = lrtable.append({'Model': \"Logistic Regression\",\n",
    "                        'F1':  f1_score(y_test, logreg_pred),\n",
    "                        'Recall': recall_score(y_test, logreg_pred),\n",
    "                        'Precision': precision_score(y_test, logreg_pred),\n",
    "                        'Accuracy': accuracy_score(y_test, logreg_pred),\n",
    "                        'ROC-AUC': roc_auc_score(y_test, logreg_pred)\n",
    "                      },\n",
    "                        ignore_index=True)\n",
    "                     \n",
    "lrtable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR Tuned Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_scaled = minmax.transform(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtest_pred = logreg.predict(testset_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtest_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregtest_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(logregtest_pred, columns=[\"predicted_probability\"])\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df.to_csv(\"lrtunedresults.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1 = LogisticRegression(penalty='l1', C=1.0, \n",
    "                              solver='liblinear', class_weight=None,\n",
    "                              max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1.fit(X_train_scaled,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1_pred = logregl1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl1.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**==================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L2 regularized logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2 = LogisticRegression(penalty='l2', C=1.0, solver='liblinear', max_iter=500, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2_pred = logregl2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logregl2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best C value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "# try c values from 0.001 to 100:\n",
    "c_settings = np.arange(0.001, 100, 0.1) \n",
    "for i in c_settings:\n",
    "    # build the model\n",
    "    clf = LogisticRegression(C=i)\n",
    "    clf.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(clf.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(clf.score(X_test, y_test))\n",
    "    \n",
    "plt.plot(c_settings, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(c_settings, test_accuracy, label=\"test accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine which evaluation metric might be best, consider how our model might be wrong. There are two possibilities for bad predictions: \n",
    "  \n",
    "  - **False positives:** When the model predicts a customer **will** churn when in fact they won't\n",
    "  - **False negatives:** When the model predicts a customer will **not** churn when in fact they will     \n",
    "\n",
    "As you know, there are a number of performance metrics aside from accuracy to choose from. Some of these include precision, recall, and F1 score. Let's examine these more closely, beginning with _precision_:\n",
    "\n",
    "$$precision = \\frac{\\text{TP}}{\\text{FP+TP}}$$\n",
    "  </br> \n",
    "\n",
    "And _recall_: \n",
    "\n",
    "$$recall = \\frac{\\text{TP}}{\\text{FN+TP}}$$  \n",
    "  </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"confusion matrix.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision represents the percentage of all our model's predicted positives that are true positives. This might not be the best metric for us to use, because it disincentivizes predicting someone will churn unless there is a high degree of certainty that they will. This could translate to a high rate of false negatives.\n",
    "\n",
    "On the other hand, recall represents the percentage of all actual positives that the model identifies as such. This also might not be the best metric to use, because it rewards predicting someone will churn even if the likelihood of their doing so is very small. This could translate to a high rate of false positives.\n",
    "\n",
    "So which is worse, false positives or false negatives? Well, we'd first have to define what _worse_ means. This is dependent on the details of the project that you're working on. For the sake of this exercise, let us suppose that we're defining it as the error that would cost the bank more money.\n",
    "\n",
    "Since we don't know the exact cost of predicting a false negative, we'll make an assumption for this exercise. We'll assume that a metric that balances precision and recall is best. The metric that helps us achieve this balance is _F1 score_, which is defined as the harmonic mean of precision and recall. \n",
    "\n",
    "$${F_{1}} = 2 \\cdot \\frac{precision \\cdot  recall}{precision + recall}$$  \n",
    "</br>\n",
    "Again, there are many metrics to choose from. The important thing is that you make an informed decision that is based on your use case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** What are the four basic parameters for evaluating the performance of a classification model?\n",
    "\n",
    "1. True positives (TP): These are correctly predicted positive values, which means the value of actual and predicted classes are positive. \n",
    "\n",
    "2. True negatives (TN): These are correctly predicted negative values, which means the value of the actual and predicted classes are negative.\n",
    "\n",
    "3. False positives (FP): This occurs when the value of the actual class is negative and the value of the predicted class is positive.\n",
    "\n",
    "4. False negatives (FN): This occurs when the value of the actual class is positive and the value of the predicted class in negative. \n",
    "\n",
    "**Reminder:** When fitting and tuning classification modeld, data professioals aim to minimize false positives and false negatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**  What do the four scores demonstrate about your model, and how do you calculate them?\n",
    "\n",
    "- Accuracy (TP+TN/TP+FP+FN+TN): The ratio of correctly predicted observations to total observations. \n",
    " \n",
    "- Precision (TP/TP+FP): The ratio of correctly predicted positive observations to total predicted positive observations. \n",
    "\n",
    "- Recall (Sensitivity, TP/TP+FN): The ratio of correctly predicted positive observations to all observations in actual class.\n",
    "\n",
    "- F1 score: The harmonic average of precision and recall, which takes into account both false positives and false negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test,logregl1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test,logregl1_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "ConfusionMatrixDisplay.from_estimator(estimator=logregl1, X=X_test, y=y_test, ax=ax, display_labels=[\"No\",\"Yes\"])\n",
    "ax.set_title('Confusion matrix of the classifier', size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "RocCurveDisplay.from_estimator(estimator=logregl1, X=X_test, y=y_test, ax=ax)\n",
    "ax.set_title('ROC Curve of the classifier', size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jaccard index\n",
    "\n",
    "Let's try the jaccard index for accuracy evaluation. we can define jaccard as the size of the intersection divided by the size of the union of the two label sets. If the entire set of predicted labels for a sample strictly matches with the true set of labels, then the subset accuracy is 1.0; otherwise it is 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard_score(y_test, logpred , pos_label=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Loss\n",
    "\n",
    "Now, let's try **log loss** for evaluation. In logistic regression, the output can be the probability of customer churn is yes (or equals to 1). This probability is a value between 0 and 1.\n",
    "Log loss(Logarithmic loss) measures the performance of a classifier where the predicted output is a probability value between 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logproba = logreg.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss(y_test, logproba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the results\n",
    "\n",
    "Print out the model's accuracy, precision, recall, and F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\", \"%.3f\" % accuracy_score(y_test, logregl1_pred))\n",
    "print(\"Precision:\", \"%.3f\" % precision_score(y_test, logregl1_pred))\n",
    "print(\"Recall:\", \"%.3f\" % recall_score(y_test, logregl1_pred))\n",
    "print(\"F1 Score:\", \"%.3f\" % f1_score(y_test, logregl1_pred))\n",
    "print(\"ROC-AUC Score:\", \"%.3f\" % roc_auc_score(y_test, logregl1_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame()\n",
    "table = table.append({'Model': \"Logistic Regression\",\n",
    "                        'F1':  f1_score(y_test, logregl1_pred),\n",
    "                        'Recall': recall_score(y_test, logregl1_pred),\n",
    "                        'Precision': precision_score(y_test, logregl1_pred),\n",
    "                        'Accuracy': accuracy_score(y_test, logregl1_pred),\n",
    "                        'ROC-AUC': roc_auc_score(y_test, logregl1_pred)\n",
    "                      },\n",
    "                        ignore_index=True)\n",
    "                     \n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation\n",
    "\n",
    "When performing supervised machine learning analysis, it is common to withhold a portion of the data to test the final model's performance. This model testing is performed on the 'unseen' data, which the model was not trained on. This withholding of a portion of the dataset for testing is called Cross-Validation. Cross-Validation can also be used to select hyper-parameters and test the final model. In this section, we will focus on the test data only.\n",
    "\n",
    "Cross-Validation also helps avoid over-fitting; a complex model could repeat the labels of the samples that it has just seen and, therefore, would have a perfect score but would fail to predict anything useful on the 'unseen' data. Furthermore, a complex model could just be modeling noise.\n",
    "\n",
    "Cross validation method involves dividing the dataset into 3 parts:\n",
    "\n",
    "*   training set - is a portion of the data used for training the model\n",
    "*   validation set - is a portion of the data used to optimize the hyper-parameters of the model. This will     be illustrated in the next lab\n",
    "*   test set - is a portion of the data used to evaluate if the model generalizes enough to work on the     \n",
    "    data it was not trained on   \n",
    "    \n",
    "`Scikit Learn` library contains many methods that can perform the splitting of the data into training, testing and validation sets. The most popular methods that we will cover in this Jupyter Notebook are:\n",
    "\n",
    "*   train_test_split - creates a single split into train and test sets\n",
    "*   K-fold - creates number of k-fold splits, allowing cross validation\n",
    "*   cross_val_score - evaluates model's score through cross validation\n",
    "\n",
    "[`cross_val_predict`](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_predict.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork783-2023-01-01) is a function that does K-fold cross validation for us, appropriately fitting and transforming at every step of the way.\n",
    "\n",
    "Note that `cross_val_predict` doesn't use the same model for all steps; the predictions for each row are made when that row is in the validation set. We really have the collected results of 3 (i.e. `kf.num_splits`) different models. \n",
    "\n",
    "When we are done, `estimator` is still not fitted. If we want to predict on _new_ data, we still have to train our `estimator`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K Fold Cross Validation\n",
    "\n",
    "Cross-validation is a resampling procedure used to evaluate machine learning models on a limited data sample.\n",
    "\n",
    "The procedure has a single parameter called k that refers to the number of groups that a given data sample is to be split into. As such, the procedure is often called k-fold cross-validation. When a specific value for k is chosen, it may be used in place of k in the reference to the model, such as k=5 becoming 5-fold cross-validation, as shown in the Diagram below. In this case, we would use K-1 (or 4 folds) for testing a 1 fold for training. K-fold is also used for hyper-parameters selection that we will discuss later.\n",
    "\n",
    "<img src=\"k-fold.png\">\n",
    "<img src = \"cross_validation_diagram.png\">\n",
    "\n",
    "In many cases, we would like to train models that are not available in Scikit-learn or are too large to fit in the memory. We can create a `KFold` object that  Provides train/test indices to split data into train/test sets in an iterative manner.\n",
    "\n",
    "`n_splits`:  A number of folds. Must be at least 2. Changed in version 0.22: n_splits default value changed from 3 to 5.\n",
    "\n",
    "`shuffle`: Indicates whether to shuffle the data before splitting into batches. Note, the samples within each split will not be shuffled.\n",
    "\n",
    "`random_state`: the random state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimate the generalization error of a machine learning model using Cross-Validation Schemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimate generalization error\n",
    "clf = cross_validate(estimator=logregl1,\n",
    "                    X=X_train,\n",
    "                    y=y_train,\n",
    "                    scoring='roc_auc',\n",
    "                    return_train_score=True,\n",
    "                    cv=kf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean test set roc-auc\n",
    "clf[\"test_score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean train set roc-auc\n",
    "clf[\"train_score\"].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Score\n",
    "\n",
    "Now, let's use *Scikit-Learn's* *K-fold cross-validation* method to see whether we can assess the performance of our model. The *K-fold cross-validation* method splits the training set into the number of folds (n_splits), as now in the Diagram above, if we have K folds, K-1 is used for training and one fold is used for testing. The input parameters are as follows:\n",
    "\n",
    "<b>estimator</b>: The object to use to `fit` the data.\n",
    "\n",
    "<b>X</b>: array-like of shape (n_samples, n_features). The data to fit. Can be for example a list, or an array.\n",
    "\n",
    "<b>y</b>: array-like of shape (n_samples,) or (n_samples, n_outputs), default=None. The target variable to try to predict in the case of supervised learning.\n",
    "\n",
    "<b>scoring</b>: A str or a scorer callable object/ function with signature scorer (estimator, X, y) which should return only a single value.  See model evaluation [documentation](https://scikit-learn.org/stable/modules/model_evaluation.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMML240ENSkillsNetwork34171862-2022-01-01#scoring-parameter) for more information.\n",
    "\n",
    "The larger the fold, the better the model performance is, as we are using more samples for training; the variance also decreases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv = cross_val_score(estimator=logreg, X=X_train, y=y_train, scoring='accuracy', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv = cross_val_score(estimator=logreg, X=X_train, y=y_train, scoring='f1', cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-1 * cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use the function 'cross_val_predict' to predict the output. The function splits up the data into the specified number of folds, with one fold for testing and the other folds are used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg_pred_cv = cross_val_predict(estimator=logreg, X=X_train[[\"disp\"]], y=y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logreg_pred_cv [0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-validated hyperparameter tuning\n",
    "\n",
    "Cross-validating a model using GridSearchCV can be done in a number of different ways. If you find notebooks online that other people have written, you'll likely soon discover this for yourself. But all variations must fulfill the same general requirements. (Refer to the [GridSearchCV documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) for further reading.)\n",
    "\n",
    "The format presented below is step-wise, making it easier to follow.\n",
    "\n",
    "* Create a dictionary of hyperparameters to search over:\n",
    "\n",
    "  - key = name of hyperparameter (string)\n",
    "  - value = values to search over (list)\n",
    "  \n",
    "* Create a dictionary of scoring metrics to capture. These metrics can be selected from scikit-learn's [built-in options](https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter) or custom-defined. For this exercise, we'll capture accuracy, precision, recall, and F1 score so we can examine all of them. The metrics are entered as strings.\n",
    "\n",
    "* Instantiate the classifier (and set the `random_state`)\n",
    "\n",
    "* Instantiate the `GridSearchCV` object. Pass as arguments:\n",
    "  - The classifier (`tuned_decision_tree`)\n",
    "  - The dictionary of hyperparameters to search over (`tree_para`)\n",
    "  - The dictionary of scoring metrics (`scoring`)\n",
    "  - The number of cross-validation folds you want (`cv=5`)\n",
    "  - The scoring metric that you want GridSearch to use when it selects the \"best\" model (i.e., the model that performs best on average over all validation folds) (`refit='f1'`*)\n",
    "\n",
    "    \\* The reason it's called `refit` is because once the algorithm finds the combination of hyperparameters that results in the best average score across all validation folds, it will then refit this model to _all_ of the training data. Remember, up until now, with a 5-fold cross-validation, the model has only ever been fit on 80% (4/5) of the training data, because the remaining 20% was held out as a validation fold.\n",
    "\n",
    "* Fit the data (`X_train`, `y_train`) to the `GridSearchCV` object (`clf`)\n",
    "\n",
    "Depending on the number of different hyperparameters you choose, the number of combinations you search over, the size of your data, and your available computing resources, this could take a long time.\n",
    "\n",
    "Now that the model is fit and cross-validated, we can use the `best_estimator_` attribute to inspect the hyperparameter values that yielded the highest F1 score during cross-validation.\n",
    "\n",
    "The `best_score_` attribute returns the best average F1 score across the different folds among all the combinations of hyperparameters. Note that if we had set `refit='recall'` when we instantiated our `GridSearchCV` object earlier, then calling `best_score_` would return the best recall score, and the best parameters might not be the same as what they are in the above cell, because the model would be selected based on a different metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "logreg = LogisticRegression(penalty='l1', C=1.0, \n",
    "                              solver='liblinear', class_weight=None,\n",
    "                              max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the hyperparameter space\n",
    "param_grid = dict(\n",
    "    class_weight=[{0:0.05, 1:0.95}, {0:0.1, 1:0.9}, {0:0.2, 1:0.8}, {0:0.3, 1:0.7}, {0:0.3, 1:0.6}],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the search (one score)\n",
    "gs1 = GridSearchCV(estimator=logreg, param_grid=param_grid, scoring='roc_auc', \n",
    "                  n_jobs=2, refit=True, cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the search (multiple scores)\n",
    "gs2 = GridSearchCV(estimator=logreg, param_grid=param_grid, scoring=scoring, \n",
    "                  n_jobs=2, refit='roc_auc', cv=5, return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best hyperparameters\n",
    "gs1.fit(X_random_train, y_random_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find best hyperparameters\n",
    "gs2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best hyperparameters are stored in an attribute\n",
    "\n",
    "gs1.best_estimator_`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs1.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the best hyperparameters are stored in an attribute\n",
    "\n",
    "gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we also find the data for all models evaluated\n",
    "\n",
    "results = pd.DataFrame(gs2.cv_results_)\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model_name (string): what you want the model to be called in the output table\n",
    "        model_object: a fit GridSearchCV object\n",
    "        metric (string): precision, recall, f1, accuracy, or auc\n",
    "  \n",
    "    Returns a pandas df with the F1, recall, precision, accuracy, and auc scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.  \n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {\n",
    "                 'precision': 'mean_test_precision',\n",
    "                 'recall': 'mean_test_recall',\n",
    "                 'f1': 'mean_test_f1',\n",
    "                 'accuracy': 'mean_test_accuracy',\n",
    "                 'roc_auc' : 'mean_test_roc_auc'\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    \n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "    roc_auc = best_estimator_results.mean_test_roc_auc\n",
    "  \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame()\n",
    "    table = table.append({'Model': model_name,\n",
    "                        'Precision': precision,\n",
    "                        'Recall': recall,\n",
    "                        'F1': f1,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'ROC-AUC' : roc_auc\n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "  \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_cv_results = make_results(\"GS Logistic Regression\", model_object=gs2, metric=\"roc_auc\")\n",
    "lr_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter=1000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = { 'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "               'penalty' : ['none','l1', 'l2', 'elasticnet'],\n",
    "               'C':  [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {'accuracy', 'precision', 'recall', 'f1', 'roc_auc'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm = RandomizedSearchCV(estimator=logreg, param_distributions = parameters, cv = 5, n_iter = 40, \n",
    "                           n_jobs=-1, scoring=scoring, refit='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "lr_randm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_randm.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_results(model_name:str, model_object, metric:str):\n",
    "    '''\n",
    "    Arguments:\n",
    "        model_name (string): what you want the model to be called in the output table\n",
    "        model_object: a fit GridSearchCV object\n",
    "        metric (string): precision, recall, f1, accuracy, or auc\n",
    "  \n",
    "    Returns a pandas df with the F1, recall, precision, accuracy, and auc scores\n",
    "    for the model with the best mean 'metric' score across all validation folds.  \n",
    "    '''\n",
    "\n",
    "    # Create dictionary that maps input metric to actual metric name in GridSearchCV\n",
    "    metric_dict = {\n",
    "                 'precision': 'mean_test_precision',\n",
    "                 'recall': 'mean_test_recall',\n",
    "                 'f1': 'mean_test_f1',\n",
    "                 'accuracy': 'mean_test_accuracy',\n",
    "                 'roc_auc' : 'mean_test_roc_auc'\n",
    "                 }\n",
    "\n",
    "    # Get all the results from the CV and put them in a df\n",
    "    cv_results = pd.DataFrame(model_object.cv_results_)\n",
    "\n",
    "    # Isolate the row of the df with the max(metric) score\n",
    "    best_estimator_results = cv_results.iloc[cv_results[metric_dict[metric]].idxmax(), :]\n",
    "\n",
    "    # Extract Accuracy, precision, recall, and f1 score from that row\n",
    "    \n",
    "    f1 = best_estimator_results.mean_test_f1\n",
    "    recall = best_estimator_results.mean_test_recall\n",
    "    precision = best_estimator_results.mean_test_precision\n",
    "    accuracy = best_estimator_results.mean_test_accuracy\n",
    "    roc_auc = best_estimator_results.mean_test_roc_auc\n",
    "  \n",
    "    # Create table of results\n",
    "    table = pd.DataFrame()\n",
    "    table = table.append({'Model': model_name,\n",
    "                        'Precision': precision,\n",
    "                        'Recall': recall,\n",
    "                        'F1': f1,\n",
    "                        'Accuracy': accuracy,\n",
    "                        'ROC-AUC' : roc_auc\n",
    "                        },\n",
    "                        ignore_index=True\n",
    "                       )\n",
    "  \n",
    "    return table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all CV scores\n",
    "lr_cv_results = make_results('Logistic Regression', lr_randm, 'roc_auc')\n",
    "lr_cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**=================================================================================================================**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyCaret Binary Classification\n",
    "\n",
    "PyCaret is an open-source, low-code machine learning library in Python that automates machine learning workflows. It is an end-to-end machine learning and model management tool that exponentially speeds up the experiment cycle and makes you more productive.\n",
    "\n",
    "Compared with the other open-source machine learning libraries, PyCaret is an alternate low-code library that can be used to replace hundreds of lines of code with a few lines only. This makes experiments exponentially fast and efficient. PyCaret is essentially a Python wrapper around several machine learning libraries and frameworks, such as scikit-learn, XGBoost, LightGBM, CatBoost, spaCy, Optuna, Hyperopt, Ray, and a few more.\n",
    "\n",
    "The design and simplicity of PyCaret are inspired by the emerging role of citizen data scientists, a term first used by Gartner. Citizen Data Scientists are power users who can perform both simple and moderately sophisticated analytical tasks that would previously have required more technical expertise.\n",
    "\n",
    "Once the setup has been successfully executed it shows the information grid containing experiment level information. \n",
    "\n",
    "- **Session id:**  A pseudo-random number distributed as a seed in all functions for later reproducibility. If no `session_id` is passed, a random number is automatically generated that is distributed to all functions.<br/>\n",
    "<br/>\n",
    "- **Target type:**  Binary, Multiclass, or Regression. The Target type is automatically detected. <br/>\n",
    "<br/>\n",
    "- **Label Encoding:**  When the Target variable is of type string (i.e. 'Yes' or 'No') instead of 1 or 0, it automatically encodes the label into 1 and 0 and displays the mapping (0 : No, 1 : Yes) for reference. In this tutorial, no label encoding is required since the target variable is of numeric type. <br/>\n",
    "<br/>\n",
    "- **Original data shape:**  Shape of the original data prior to any transformations. <br/>\n",
    "<br/>\n",
    "- **Transformed train set shape :**  Shape of transformed train set <br/>\n",
    "<br/>\n",
    "- **Transformed test set shape :**  Shape of transformed test set <br/>\n",
    "<br/>\n",
    "- **Numeric features :**  The number of features considered as numerical. <br/>\n",
    "<br/>\n",
    "- **Categorical features :**  The number of features considered as categorical. <br/>\n",
    "\n",
    "A typical workflow in PyCaret consist of following 5 steps in this order:\n",
    "\n",
    "## **Setup** ➡️ **Compare Models** ➡️ **Analyze Model** ➡️ **Prediction** ➡️ **Save Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Setup\n",
    "This function initializes the experiment in PyCaret and creates the transformation pipeline based on all the parameters passed in the function. Setup function must be called before executing any other function. It takes two required parameters: `data` and `target`. All the other parameters are optional and are used for configuring data preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = setup(data=df, target = 'default', session_id = 0, train_size=0.8, test_data=None, preprocess=True,\n",
    "         imputation_type=None, normalize = True, normalize_method = 'minmax', fold=5, n_jobs=2, \n",
    "         fix_imbalance=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(get_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_config('y_transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_config('X_train_transformed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare Models\n",
    "\n",
    "This function trains and evaluates the performance of all the estimators available in the model library using cross-validation. The output of this function is a scoring grid with average cross-validated scores. Metrics evaluated during CV can be accessed using the `get_metrics` function. Custom metrics can be added or removed using `add_metric` and `remove_metric` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(compare_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check available models\n",
    "models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare baseline models\n",
    "# best_model = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_linear_models = compare_models(include = ['lr', 'nb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function above has return trained model object as an output. The scoring grid is only displayed and not returned. If you need access to the scoring grid you can use `pull` function to access the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_linear_models_results = pull()\n",
    "compare_linear_models_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default `compare_models` return the single best performing model based on the metric defined in the `sort` parameter. Let's change our code to return 3 top models based on `Recall`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_auc_models_top3 = compare_linear_models(sort = 'AUC', n_select = 3)\n",
    "best_auc_models_top3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Model\n",
    "\n",
    "You can use the `plot_model` function to analyzes the performance of a trained model on the test set. It may require re-training the model in certain cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot confusion matrix\n",
    "plot_model(compare_linear_models, plot = 'confusion_matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot AUC\n",
    "plot_model(compare_linear_models, plot = 'auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot feature importance\n",
    "plot_model(compare_linear_models, plot = 'feature')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(compare_linear_models, plot = 'feature_all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(compare_linear_models, plot = 'rfe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(compare_linear_models, plot = 'parameter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check docstring to see available plots \n",
    "# help(plot_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction\n",
    "The `predict_model` function returns `prediction_label` and `prediction_score` (probability of the predicted class) as new columns in dataframe. When data is `None` (default), it uses the test set (created during the setup function) for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "holdout_pred = predict_model(compare_linear_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show predictions df\n",
    "holdout_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same function works for predicting the labels on unseen dataset. Let's create a copy of original data and drop the `Class variable`. We can then use the new data frame without labels for scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy data and drop Class variable\n",
    "\n",
    "new_data = testset.copy()\n",
    "#new_data.drop('Class variable', axis=1, inplace=True)\n",
    "new_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict model on new_data\n",
    "predictions = predict_model(compare_linear_models, data = new_data)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = predictions[['prediction_label']]\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.rename(columns={'prediction_label': 'predicted_probability'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_df.to_csv(\"lrpycaretresults.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Tune Model\n",
    "\n",
    "This function tunes the hyperparameters of the model. The output of this function is a scoring grid with cross-validated scores by fold. The best model is selected based on the metric defined in optimize parameter. Metrics evaluated during cross-validation can be accessed using the `get_metrics` function. Custom metrics can be added or removed using `add_metric` and `remove_metric` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model\n",
    "\n",
    "Finally, you can save the entire pipeline on disk for later use, using pycaret's `save_model` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save pipeline\n",
    "save_model(best, 'my_first_pipeline')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pipeline\n",
    "loaded_best_pipeline = load_model('my_first_pipeline')\n",
    "loaded_best_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Python code done by Dennis Lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
